{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1f1536",
   "metadata": {},
   "outputs": [],
   "source": [
    "myth_entities = {\n",
    "    \"Zeus\": [\"Zeus\"],\n",
    "    \"Apollo\": [\"Apollo\", \"Phoebus\"],\n",
    "    \"Athena\": [\"Athena\", \"Pallas\"],\n",
    "    \"Artemis\": [\"Artemis\"],\n",
    "    \"Hades\": [\"Hades\", \"Plouton\"],\n",
    "    \"Poseidon\": [\"Poseidon\"],\n",
    "    \"Demeter\": [\"Demeter\"],\n",
    "    \"Hera\": [\"Hera\"],\n",
    "    \"Hermes\": [\"Hermes\"],\n",
    "    \"Ares\": [\"Ares\"],\n",
    "    \"Dionysus\": [\"Dionysus\", \"Bacchus\"],\n",
    "    \"Hephaestus\": [\"Hephaestus\", \"Vulcan\"],\n",
    "    # You can add heroes too, like \"Heracles\": [\"Heracles\", \"Hercules\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fe2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "import csv\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 2_000_000\n",
    "geolocator = Nominatim(user_agent=\"myth_mapper\")\n",
    "\n",
    "# Scrape Apollodorus\n",
    "url = \"https://www.theoi.com/Text/Apollodorus1.html\"\n",
    "soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "apollodorus_text = soup.get_text(separator=\" \")\n",
    "\n",
    "# Load Homer texts\n",
    "odyssey = requests.get(\"https://www.gutenberg.org/files/1727/1727-0.txt\").text\n",
    "iliad = requests.get(\"https://www.gutenberg.org/files/6130/6130-0.txt\").text\n",
    "\n",
    "sources = {\n",
    "    \"Apollodorus\": apollodorus_text,\n",
    "    \"Odyssey\": odyssey,\n",
    "    \"Iliad\": iliad\n",
    "}\n",
    "\n",
    "myth_entities = {\n",
    "    \"Zeus\": [\"Zeus\"],\n",
    "    \"Apollo\": [\"Apollo\", \"Phoebus\"],\n",
    "    \"Athena\": [\"Athena\", \"Pallas\"],\n",
    "    \"Artemis\": [\"Artemis\"],\n",
    "    \"Hades\": [\"Hades\", \"Plouton\"],\n",
    "    \"Poseidon\": [\"Poseidon\"],\n",
    "    \"Demeter\": [\"Demeter\"],\n",
    "    \"Hera\": [\"Hera\"],\n",
    "    \"Hermes\": [\"Hermes\"],\n",
    "    \"Ares\": [\"Ares\"],\n",
    "    \"Dionysus\": [\"Dionysus\", \"Bacchus\"],\n",
    "    \"Hephaestus\": [\"Hephaestus\", \"Vulcan\"]\n",
    "}\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "for source_name, raw_text in sources.items():\n",
    "    doc = nlp(raw_text)\n",
    "    ents = [(ent.text.strip(), ent.start_char, ent.label_) for ent in doc.ents if ent.label_ in (\"GPE\", \"LOC\")]\n",
    "\n",
    "    for place, pos, _ in ents:\n",
    "        context_window = raw_text[max(0, pos-200):pos+200].lower()\n",
    "        associated_god = None\n",
    "        for god, aliases in myth_entities.items():\n",
    "            if any(alias.lower() in context_window for alias in aliases):\n",
    "                associated_god = god\n",
    "                break\n",
    "\n",
    "        if not associated_god:\n",
    "            continue\n",
    "\n",
    "        key = (place, associated_god)\n",
    "\n",
    "        if key not in output_dict:\n",
    "            try:\n",
    "                loc = geolocator.geocode(place)\n",
    "                if loc:\n",
    "                    output_dict[key] = {\n",
    "                        \"Place\": place,\n",
    "                        \"Latitude\": loc.latitude,\n",
    "                        \"Longitude\": loc.longitude,\n",
    "                        \"God\": associated_god,\n",
    "                        \"Source\": source_name,\n",
    "                        \"Frequency\": 1\n",
    "                    }\n",
    "                    sleep(1)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            output_dict[key][\"Frequency\"] += 1\n",
    "\n",
    "# Convert dictionary to list\n",
    "output_data = list(output_dict.values())\n",
    "\n",
    "# Optional: Write to CSV\n",
    "with open(\"myth_locations_with_frequency.csv\", \"w\", newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"Place\", \"Latitude\", \"Longitude\", \"God\", \"Source\", \"Frequency\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "840e5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import spacy\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from time import sleep\n",
    "# import csv\n",
    "\n",
    "# # Load spaCy and geocoder\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.max_length = 2_000_000\n",
    "# geolocator = Nominatim(user_agent=\"myth_mapper\")\n",
    "\n",
    "# # Scrape Apollodorus\n",
    "# soup = BeautifulSoup(requests.get(\"https://www.theoi.com/Text/Apollodorus1.html\").text, \"html.parser\")\n",
    "# apollodorus_text = soup.get_text(separator=\" \")\n",
    "\n",
    "# # Homer texts\n",
    "# odyssey = requests.get(\"https://www.gutenberg.org/files/1727/1727-0.txt\").text\n",
    "# iliad = requests.get(\"https://www.gutenberg.org/files/6130/6130-0.txt\").text\n",
    "\n",
    "# sources = {\n",
    "#     \"Apollodorus\": apollodorus_text,\n",
    "#     \"Odyssey\": odyssey,\n",
    "#     \"Iliad\": iliad\n",
    "# }\n",
    "\n",
    "# # Gods and aliases\n",
    "# myth_entities = {\n",
    "#     \"Zeus\": [\"Zeus\"],\n",
    "#     \"Apollo\": [\"Apollo\", \"Phoebus\"],\n",
    "#     \"Athena\": [\"Athena\", \"Pallas\"],\n",
    "#     \"Artemis\": [\"Artemis\"],\n",
    "#     \"Hades\": [\"Hades\", \"Plouton\"],\n",
    "#     \"Poseidon\": [\"Poseidon\"],\n",
    "#     \"Demeter\": [\"Demeter\"],\n",
    "#     \"Hera\": [\"Hera\"],\n",
    "#     \"Hermes\": [\"Hermes\"],\n",
    "#     \"Ares\": [\"Ares\"],\n",
    "#     \"Dionysus\": [\"Dionysus\", \"Bacchus\"],\n",
    "#     \"Hephaestus\": [\"Hephaestus\", \"Vulcan\"]\n",
    "# }\n",
    "\n",
    "# # Track frequency of (Place, God) pairs\n",
    "# pair_counter = defaultdict(lambda: {\"count\": 0, \"Latitude\": None, \"Longitude\": None, \"Sources\": set()})\n",
    "\n",
    "# for source_name, raw_text in sources.items():\n",
    "#     doc = nlp(raw_text)\n",
    "#     ents = [(ent.text, ent.start_char, ent.label_) for ent in doc.ents if ent.label_ in (\"GPE\", \"LOC\")]\n",
    "\n",
    "#     for place, pos, _ in ents:\n",
    "#         context_window = raw_text[max(0, pos-200):pos+200].lower()\n",
    "#         associated_god = None\n",
    "#         for god, aliases in myth_entities.items():\n",
    "#             if any(alias.lower() in context_window for alias in aliases):\n",
    "#                 associated_god = god\n",
    "#                 break\n",
    "\n",
    "#         if not associated_god:\n",
    "#             continue\n",
    "\n",
    "#         key = (place.strip(), associated_god)\n",
    "\n",
    "#         # If first time seeing the pair, geocode it\n",
    "#         if pair_counter[key][\"count\"] == 0:\n",
    "#             try:\n",
    "#                 loc = geolocator.geocode(place)\n",
    "#                 if loc:\n",
    "#                     pair_counter[key][\"Latitude\"] = loc.latitude\n",
    "#                     pair_counter[key][\"Longitude\"] = loc.longitude\n",
    "#                     sleep(1)\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#         pair_counter[key][\"count\"] += 1\n",
    "#         pair_counter[key][\"Sources\"].add(source_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3bcc50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: 'Frequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m writer.writeheader()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m output_data:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/csv.py:164\u001b[39m, in \u001b[36mDictWriter.writerow\u001b[39m\u001b[34m(self, rowdict)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwriterow\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writer.writerow(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrowdict\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/csv.py:159\u001b[39m, in \u001b[36mDictWriter._dict_to_list\u001b[39m\u001b[34m(self, rowdict)\u001b[39m\n\u001b[32m    157\u001b[39m     wrong_fields = rowdict.keys() - \u001b[38;5;28mself\u001b[39m.fieldnames\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdict contains fields not in fieldnames: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m                          + \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict.get(key, \u001b[38;5;28mself\u001b[39m.restval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fieldnames)\n",
      "\u001b[31mValueError\u001b[39m: dict contains fields not in fieldnames: 'Frequency'"
     ]
    }
   ],
   "source": [
    "with open(\"mythology_locations.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Place\", \"Latitude\", \"Longitude\", \"God\", \"Source\"])\n",
    "    writer.writeheader()\n",
    "    for row in output_data:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeda016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"mythology_locations_with_counts.csv\", \"w\", newline=\"\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"Place\", \"God\", \"Latitude\", \"Longitude\", \"Frequency\", \"Sources\"])\n",
    "\n",
    "#     for (place, god), data in pair_counter.items():\n",
    "#         writer.writerow([\n",
    "#             place,\n",
    "#             god,\n",
    "#             data[\"Latitude\"],\n",
    "#             data[\"Longitude\"],\n",
    "#             data[\"count\"],\n",
    "#             \", \".join(sorted(data[\"Sources\"]))\n",
    "#         ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
